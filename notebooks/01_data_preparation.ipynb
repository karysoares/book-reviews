{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import sample\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df_review = pd.read_csv(r\"/home/karysoares/Documents/book-reviews/data/books_rating.csv\")\n",
    "df_books_data = pd.read_csv(r\"/home/karysoares/Documents/book-reviews/data/books_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se tentarmos comparar os \"Title\" diretamente, estaremos comparando strings - uma operação custosa.\n",
    "# Então, vamos converter o \"title\" para hashes. Comparar hashes é uma operação muito menos custosa do que \n",
    "# comparar strings. Isso poderia ser feito de outro modo, como usando 'merge', mas desse modo as operações\n",
    "# ficam mais transparentes.\n",
    "df_review['title_hash'] = df_review['Title'].apply(lambda x: hash(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reviews(title):\n",
    "    title_hash = hash(title)\n",
    "    return df_review[df_review['title_hash'] == title_hash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7790b253a6f4d068bfa8723a13074b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/212404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_books_data['review'] = df_books_data['Title'].progress_apply(find_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos já preparar a média dos reviews para adiantar essa operação nos outros notebooks\n",
    "df_books_data['review_mean'] = df_books_data['review'].apply(lambda x: x['score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setando o Index do df_review para facilitar a indexação em uma db relacional\n",
    "df_review.set_index(\"Id\", drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Vamos salvar os dados para garantir que as operações não sejam em vão\n",
    "# Como simplesmente adicionamos um recorte do df_review diretamente no df_books_data, \n",
    "# precisaremos simplificar a relação entre os datasets. Para isso, substituiremos \n",
    "# o dataframe por uma lista de ids \n",
    "\n",
    "## Aqui nós iremos guardar os ids como uma string representando uma lista. \n",
    "## Sqlite suporta json_fields, mas guardá-lo utilizando pandas seria bem chato. \n",
    "## Como carregaremos novamente com o pandas, só precisaremos converter os valores do outro lado.\n",
    "df_books_data['review_ids'] = df_books_data['review'].apply(lambda x: str(list(x['Id'])))\n",
    "# Não queremos salvar todo o dataframe, então vamos removê-lo do df_books_data\n",
    "del df_books_data['review']\n",
    "\n",
    "\n",
    "engine = create_engine(\"sqlite:///../books.db\")\n",
    "df_review.to_sql(\"books_review\", engine, if_exists=\"replace\", index=True) # queremos que o index do dataframe seja utilizado aqui.\n",
    "df_books_data.to_sql(\"books_data\", engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books_data = df_books_data[df_books_data['description'].notnull()]\n",
    "df_books_data = df_books_data[df_books_data['categories'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como todos os resultados só tem uma categoria, vamos colapsá-la em uma string (ao invés de uma lista)\n",
    "df_books_data['categories'] = df_books_data['categories'].apply(eval)\n",
    "print(df_books_data['categories'].apply(len).max())\n",
    "df_books_data['categories'] = df_books_data['categories'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": df_books_data['description'],\n",
    "        \"label\": df_books_data['categories'].str.lower(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muitas labels aparecem poucas vezes e devemos considerá-las como \"dados ruins\". Iremos eliminar todas as linhas que tiverem labels que aparecem menos de 100 vezes.\n",
    "label_count = df_category['label'].value_counts()\n",
    "label_count = label_count[label_count >= 100]\n",
    "df_category = df_category[df_category['label'].isin(label_count.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_category.sample(frac=0.2), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../data/category_train.csv', index=False)\n",
    "test.to_csv('../data/category_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = pd.DataFrame({\n",
    "    \"text\": df_review['text'],\n",
    "    \"label\": df_review['score'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total de linhas: \", df_sentiment.size)\n",
    "print(\"Total de linhas com text\", df_sentiment[df_sentiment['text'].notnull()].size)\n",
    "print(\"Total de linhas com score\", df_sentiment[df_sentiment['label'].notnull()].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = df_sentiment[df_sentiment['text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment.label = df_sentiment.label.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_sentiment.sample(frac=0.5), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../data/sentiment_train.csv', index=False)\n",
    "test.to_csv('../data/sentiment_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment['label'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
